---
title: 如何使用 Docker Swarm 部署服务集群
date: 2023-08-24T14:47:00+08:00
tags: [Docker, Docker Swarm, DevOps]
description: 我们的系统属于中小规模，一直没有上 k8s，觉得有点大材小用。从年初我将所有服务迁移到 Docker Swarm 以来，服务一直运行很稳定，还没有出现因架构导致的重大问题，所以写篇文章记录一下。
---

import Note from "@components/md/Note.astro";

# 目录

# 什么是 Docker Swarm

[Docker Swarm](https://docs.docker.com/engine/swarm/) 是内置在 `Docker` 中的容器集群编排工具，它为 `Docker` 补足了服务治理方面的能力，提供了路由网格、服务发现、负载均衡、动态伸缩、滚动更新等功能。

简单来说，如果你有很少几个服务运行，那么使用 `Docker` 容器管理应用即可。当你的服务越来越多时，就会需要一个工具来管理所有的容器，而 `Docker Swarm` 就是 `Docker` 内建的一种解决方案。

在 `Kubernetes` 已经成为事实上业界标准的今天，`Docker Swarm` 无论功能还是社区活跃度都无法与之匹敌，但它仍在市场上占有一席之地。根据 `RightScale` 最新的市场统计结果（State of Cloud Report 2023），`Docker Swarm` 是除了 k8s（商业或自建）以外使用率最高的容器管理平台。

![RightScale - State of Cloud Report 2023](@assets/docker-swarm-deploy/image.png)

`Docker Swarm` 相对其他容器编排工具来说有以下几个特点

**原生支持**

Docker Swarm 因为内置在 Docker 中，是可以开箱即用的，安装好了 Docker 就可以立即启动 Swarm 了。

**配置简单**

Docker Swarm 可以通过 `docker-compose.yaml` 清单文件管理服务，如果你之前使用过 `docker compose`，那么只需要添加几行配置就可以把服务部署到 Swarm 中。

**学习曲线平滑**

因为 Docker Swarm 并没有跳脱出 Docker 这个框架，所以相比于学习 Kubernetes 中的一大堆专有名词和“新概念”，Docker Swarm 的学习难度是非常低的。

**兼容 Standalone 容器**

部署在 Docker Swarm 中的服务可以很好的和直接运行在 Docker 上的独立容器共存，所以只将一部分容器服务部署到 Swarm 中也是可以的。

# 快速部署

## 初始化集群

`Docker Swarm` 集群中的主机称为节点 `Node`，他们有两种角色 `Manager` 管理节点和 `Worker` 工作节点，管理节点负责将工作负载分发到工作节点上，并且一个集群中可以有多个 Manager 和多个 Worker，它们的关系如下图

![Docker Swarm 中的节点关系](@assets/docker-swarm-deploy/image-1.png)

使用下面的命令初始化一个 `Manager` 节点

```bash
$ docker swarm init
```

执行成功后会看到这样一段输出：

```diff
Swarm initialized: current node (dxn1zxxxxx) is now a manager.

To add a worker to this swarm, run the following command:

+    docker swarm join \
+    --token SWMTKN-1-49njxxxxx \
+    192.168.99.100:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.
```

把它提示的这行命令在同一个局域网下的其他主机上运行，即可作为 `Worker` 节点加入到集群中

```bash
$ docker swarm join \
    --token SWMTKN-1-49njxxxxx \
    192.168.99.100:2377
```

<Note type="info">
  如果是在云上操作，记得在安全组中开放 `2377/tcp` `7946/tcp` `7946/udp`
  `4789/udp`
  这几个端口，或者把同一个集群的实例全部加入到同一个安全组中，才可以正常建立
  Swarm 集群。
</Note>

使用 `node ls` 命令可以查看集群中节点概况

```bash
$ docker node ls
ID                            HOSTNAME   STATUS    AVAILABILITY   MANAGER STATUS   ENGINE VERSION
9j68exjopxe7wfl6yuxml7a7j     worker1    Ready     Active                          20.10.5
1vyu1dscvcmnoaylch05u7xdd *   manager    Ready     Active         Leader           20.10.5
```

## 部署服务

使用 `docker service` 命令可以管理 Swarm 服务，在管理节点上执行下面的命令启动一个 `Nginx` 服务

```bash
$ docker service create --name my_web --replicas 3 -p 8080:80 nginx
```

这样我们就创建了一个具有 3 个实例（有 3 个容器运行）的 nginx 服务，并且开放了容器的 80 端口到**所有节点**的 `8080` 端口上，此时我们访问任何一个节点的 8080 端口，都可以访问到 nginx 服务。

```bash
# 访问本地的 8080 端口
$ curl http://127.0.0.1:8080
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
...
</html>
```

使用 `service ls` 命令查看服务的概况

```bash
$ docker service ls
ID             NAME     MODE         REPLICAS   IMAGE          PORTS
od2qgvi81qf5   my_web   replicated   3/3        nginx:latest   *:8080->80/tcp
```

使用 `service ps` 命令查看服务的具体状态

```bash
$ docker service ps my_web
ID             NAME       IMAGE          NODE      DESIRED STATE   CURRENT STATE            ERROR     PORTS
iqr97uub64o7   my_web.1   nginx:latest   worker1   Running         Running 1 minutes ago
h3doosl9n0bx   my_web.2   nginx:latest   manager   Running         Running 1 minutes ago
bkozkbce1wg8   my_web.3   nginx:latest   worker1   Running         Running 1 minutes ago
```

可以看到这个服务有 3 个实例，在 Swarm 中这些实例叫做 `Task` 任务，管理节点会将任务分配到不同的节点上执行，上面的 `NODE` 列显示的就是任务由哪个节点负责。

![Task、Service和Node之间的关系](@assets/docker-swarm-deploy/image-2.png)

## 服务发现

当我们访问节点的 8080 端口时，我们实际上连接到了三个实例的其中一个，Swarm 帮我们将请求路由到负载较小的实例上。

具体来说，Swarm 默认的服务发现是通过 `vip` （虚拟 IP）实现的，它根据节点上的连接数量判断节点负载来实现负载均衡，这使客户端的多次请求可能会被不同的实例接收。关于 Swarm 服务发现的更多细节可以在[这里](https://docs.docker.com/engine/swarm/networking/#configure-service-discovery)找到。

<Note type="warning">
  `Docker Swarm` 的服务发现只适用于外部客户端请求，它并没有很好的实现服务之间的服务发现，例如，service1 通过 `http://service2:80` 访问 service2 时，是直接通过 DNS 获取到一个实例地址的，这个过程不会有负载均衡。
  <br />
  不过服务间也可以通过宿主机端口通信，比如 service2 开放了 80 端口到宿主机的 8080 端口上，那么 service1 就可以通过 `http://host.docker.internal:8080` 来访问 service2 了。注意 service1 需要配置 `host.docker.internal:host-gateway` 这个 extra hosts 才可以生效。

</Note>

## 服务日志

使用 `service logs` 命令可以查看服务的日志。服务上多个实例的日志会合并到一起。

```bash
$ docker service logs my_web
my_web.2.h3doosl9n0bx@manager    | /docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
my_web.2.h3doosl9n0bx@manager    | /docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
my_web.2.h3doosl9n0bx@manager    | /docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
my_web.2.h3doosl9n0bx@manager    | 10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
my_web.2.h3doosl9n0bx@manager    | 10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
my_web.1.iqr97uub64o7@worker1    | /docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
my_web.1.iqr97uub64o7@worker1    | /docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
my_web.1.iqr97uub64o7@worker1    | /docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
my_web.1.iqr97uub64o7@worker1    | 10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
my_web.1.iqr97uub64o7@worker1    | 10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
...
```

# 服务堆

只部署一两个服务时使用 `docker service` 命令很方便，一旦系统中的服务越来越多，我们就需要一个工具来管理服务了。

`docker stack` 就是 Swarm 用来批量管理服务的工具，`docker stack` 之于 service 正如 `docker compose` 之于 container。

## 使用 compose 文件管理服务

通过命令管理服务的方式不仅效率低，也不利于批量管理。`docker stack` 采用 `compose` 文件管理集群配置，例如下面的文件定义了 nginx 服务的各项细节

```yaml
# docker-compose.yaml
version: "3.8"

services:
  another_web:
    image: nginx
    ports:
      - 8080:80
    deploy:
      mode: replicated
      replicas: 3
```

在这个文件所在目录下，执行下面的命令就可以启动这个 stack

```bash
$ docker stack deploy -c docker-compose.yml my-stack
```

<Note type="info">
  如果镜像来自非官方的 registry，需要添加 `--with-registry-auth` 参数。
</Note>

使用 `stack ls` 命令查看 stack 的概况

```bash
$ docker stack ls
NAME       SERVICES   ORCHESTRATOR
my-stack   1          Swarm
```

使用 `stack ps` 命令查看这个 stack 的详细信息

```bash
$ docker stack ps guet-server-stack
ID             NAME                     IMAGE          NODE      DESIRED STATE   CURRENT STATE         ERROR     PORTS
yjkp59sf2ask   my-stack_another_web.1   nginx:latest   worker1   Running         Running 1 minutes ago
hcee8c0agbaw   my-stack_another_web.2   nginx:latest   manager   Running         Running 1 minutes ago
j0dax7si8fy4   my-stack_another_web.3   nginx:latest   worker1   Running         Running 1 minutes ago
```

一个 `compose` 文件中可以定义多个服务，例如下面这个 `WordPress` 服务

```yaml
version: "3.8"

services:
  wordpress:
    image: wordpress
    ports:
      - 8080:80
    networks:
      - overlay
    environment:
      WORDPRESS_DB_HOST: db:3306
      WORDPRESS_DB_USER: wordpress
      WORDPRESS_DB_PASSWORD: wordpress
    deploy:
      mode: replicated
      replicas: 3

  db:
    image: mysql:8.0
    networks:
      - overlay
    volumes:
      - db-data:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: somewordpress
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD: wordpress
    deploy:
      mode: global

volumes:
  db-data:
networks:
  overlay:
```

这个文件定义了一个具有 3 个实例的 wordpress 服务和一个全局唯一实例的 mysql 服务。它们共同加入 `overlay` 这个网络，所以 wordpress 服务可以通过 `db:3306` 地址访问到数据库。

<Note type="info">
  这里的 `MySQL`
  服务必须是单一实例，因为没有给它配置主从结构，并且挂载了数据到本地目录。也因此可以直接通过
  `db:3306` 访问到它，不需要经过负载均衡。
</Note>

## 服务升级

### 通过命令升级

对于使用 `service create` 创建的服务，我们可以通过 `service update` 命令升级

```bash
$ docker service update --image nginx:1.25.3-alpine nginx
```

`--image` 参数指定了服务升级的镜像，还可以通过 `--env-add` `--publish-add` 等参数来更新环境变量、端口等。

其他参数的详细用法可以通过 `docker service update -h` 查看。

### 升级 stack 中的服务

修改 `compose` 文件中的 `image` 字段，然后重新执行 `docker stack deploy` 命令即可。

### 滚动升级

通过指定 `compose` 文件中的 `deploy.update_config` 配置，可以控制滚动更新的行为

```yaml
deploy:
  update_config:
    parallelism: 2 # 每次更新 2 个实例
    delay: 10s # 每组容器更新后等待 10 秒
    order: stop-first # 操作的执行顺序
```

配置的详细说明

- `parallelism`: 每次更新的容器数量
- `delay`: 每组容器更新后的等待时长
- `failure_action`: 更新失败后的操作，可选值有 continue（继续更新）rollback（回滚）pause（暂停更新），默认为 pause
- `monitor`: 更新后检查是否失败的时长（默认为 0）
- `max_failure_ratio`: 更新期间可容忍的故障率
- `order`: 操作的执行顺序，可选值有 stop-first（先停止旧实例再启动新实例） start-first（先启动新实例再停止旧实例，运行中的任务会短暂重叠）（默认为 stop-first）

## 服务回滚

使用 stack 管理服务时一般不需要手动回滚，因为滚动更新配置的 `failure_action` 可以自动回滚有问题的服务。

也可以使用 `service rollback` 命令手动回滚服务

```bash
$ docker service rollback my-service
```

回滚时的具体行为可以通过 `compose` 文件的 `deploy.rollback_config` 配置

```yaml
deploy:
  rollback_config:
    parallelism: 2 # 每次回滚 2 个实例
    delay: 10s # 每组容器回滚后等待 10 秒
    order: stop-first # 操作的执行顺序
```

回滚配置和 `update_config` 相同，只有 `failure_action` 字段不可以指定为 `rollback`。

## 服务扩缩容

使用 stack 管理服务时，直接修改 `compose` 文件的 `replicas` 数量然后执行 `docker stack deploy` 即可扩缩容。

使用 `service create` 创建的服务可以通过 `service scale` 对服务进行扩缩容

```bash
$ docker service scale my-service=10
```

<Note type="info">Docker Swarm 没有自动扩缩容机制。</Note>

## 服务健康状态

通过指定 `compose` 文件中的 `healthcheck` 配置，可以对服务进行健康状态检查

```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost"] # 检查健康状态的命令，命令成功则服务健康
  interval: 1m30s # 健康状态检查的时间间隔
  timeout: 10s # 命令超时时间
  retries: 3 # 重试次数
  start_period: 40s # 服务启动需要的时间
  start_interval: 5s # 服务启动期间的健康状态检查间隔
```

对于 http 服务，一个检查服务接口 200 的命令可以是

```yaml
healthcheck:
  test: [
      "CMD-SHELL",
      "curl -o /dev/null -sw '%{http_code}\n' 127.0.0.1:8000/ping | grep 200",
    ] # 将 127.0.0.1:8000/ping 替换为服务的实际接口即可
```

如果镜像中没有 `curl`，也可以使用 `wget` 命令检查

```yaml
healthcheck:
  test: [
      "CMD-SHELL",
      "wget --spider -S '127.0.0.1:8000/ping' 2>&1 | grep 'HTTP/' | awk '{print $$2}' | grep 200",
    ] # 将 127.0.0.1:8000/ping 替换为服务的实际接口即可
```

<Note type="warning">
  健康状态检查的时间间隔不要设置的过短，建议将 `interval` 设置为 30s
  或更长，否则可能会导致 CPU 占用过高。  
  这是 Docker 的 BUG 导致的，具体可以看这两个 Issue
[moby/moby#39102](https://github.com/moby/moby/issues/39102)
[moby/moby#39388](https://github.com/moby/moby/issues/39388) 。

</Note>

### 服务重启策略

服务健康检查失败时，Docker Swarm 可以自动重启服务，具体行为可以通过 `compose` 文件中的 `deploy.restart_policy` 配置

```yaml
deploy:
  restart_policy:
    condition: on-failure # 服务健康检查失败时重启
    delay: 5s # 每次尝试重启的时间间隔
    max_attempts: 3 # 最大重试次数
    window: 120s # 确定重启是否成功的等待时长（默认为 0）
```

## 服务配置管理

在分布式集群上，传统的配置文件分发方式（打包进镜像、volume挂载、环境变量等）都存在一些问题。试想，如果挂载某个目录为镜像的配置文件目录，那么每一个节点上都要放一个相同的目录上去，而且服务升级时还要同时更新配置文件的目录，这显然增加了工作复杂度。

Docker Swarm 提供了 `docker config` 和 `docker secret` 两种方式来管理分布式集群服务的配置文件。

### 使用 docker config 管理配置

一个简单的例子，给 redis 创建一个 docker config

```bash
echo "port 6379" | docker config create redis-config -
```

或者将本地的 `redis.conf` 文件创建为 docker config

```bash
docker config create redis-config ./redis.conf
```

创建后，Swarm 集群上的所有节点都可以访问到这个配置文件，下面将配置加入到 `compose` 中

```yaml
services:
  redis:
    image: redis
    configs:
      - source: redis-config # 配置名
        target: /usr/local/etc/redis/redis.conf # 将配置放置到这个路径

configs:
  redis-config:
    external: true # 已经在外部由命令行创建好
```

在执行 `docker stack deploy` 后，配置文件就会在所有节点的所有实例上生效了。

`docker config` 也支持直接在 `compose` 文件中创建，而无需预先执行 `docker config create`，例如：

```yaml
services:
  redis:
    image: redis
    configs:
      - source: redis-config
        target: /usr/local/etc/redis/redis.conf

configs:
  redis-config:
    file: ./redis.conf # 在 compose 文件中加载 docker config
```

### 使用 docker secret 管理密钥

`docker secret` 用来管理服务的敏感数据，包括：

- 用户名和密码
- TLS 证书和密钥
- SSH 密钥等

和 `docker config` 类似，使用 `docker secret create` 来创建一个 secret

```bash
echo "some secret content" | docker secret create my-secret -
```

或者直接定义在 `compose` 文件中

```yaml
services:
  mysql:
    image: mysql
    secrets:
      - my-secret # secret 文件会默认挂载到 /run/secrets/<secret name> 路径
    environment:
      MYSQL_DATABASE: wordpress
      MYSQL_USER: wordpress
      MYSQL_PASSWORD_FILE: /run/secrets/my-secret # 使用 secret 作为密码
      MYSQL_ROOT_PASSWORD_FILE: /run/secrets/my-secret # 使用 secret 作为密码
    deploy:
      mode: global

secrets:
  my-secret:
    file: ./secret.txt
```

<Note type="info">
  Docker 通过 TLS 加密连接传输 secret 的内容，并存储到加密的 Raft log
  中。当创建的容器具有 secret 访问权限时，解密的密钥才会被挂载到容器中。
</Note>

### 配置文件的版本管理

`docker config` 和 `docker secret` 和 volume 挂载有些类似，区别是 config 和 secret 一旦创建就不会再更改了，所以如果想要更新它们，就要执行这几步：

1. 创建 config_v2
2. 重新 deploy 服务，并使用 config_v2
3. 删除 config_v1

`compose` 文件支持通过环境变量设置 config 和 secret，例如

```yaml
secrets:
  my-secret:
    name: my-secret-${VERSION} # 通过 VERSION 环境变量设置版本号
    file: ./secret.txt
```

我的公司系统将配置文件放到了 github 管理，所以可以通过 git commit id 来作为配置文件版本号：

```bash
export GIT_REF=$(git rev-parse --short HEAD)
```

```yaml
secrets:
  my-secret:
    name: my-secret-${GIT_REF}
    file: ./secret.txt
```

# 多环境部署

一个常见的多环境部署方案是 `local` `staging` `production` 三环境部署。`local` 是开发人员在本地开发和测试使用的，`staging` 是系统预览环境，用来在系统上线前测试并发现问题，`production` 环境则是线上生产环境。

这三个环境很可能只有部分参数不同，例如 replicas 数量、数据库的用户名密码、开放端口等。而不太重要的一些参数（比如滚动更新配置、labels等）很有可能是共用的，如果把每个环境的配置都分别保存为一个 `yaml` 文件未免有些啰嗦，一旦有变更还要修改多个文件。

这时我们就可以拆分 `compose` 文件，像下面这样

```yaml
# base.yaml 文件
version: "3.8"

services:
  # wordpress 服务的公共配置
  wordpress:
    ports:
      - 8080:80
    networks:
      - overlay
    deploy:
      restart_policy:
        condition: any
        delay: 5s
        max_attempts: 3
        window: 120s
      rollback_config:
        parallelism: 1
        delay: 0s
        monitor: 10s
        order: stop-first
      update_config:
        parallelism: 1
        delay: 10s
        monitor: 10s
        order: start-first

networks:
  overlay:
```

```yaml
# staging.yaml 文件
version: "3.8"

services:
  wordpress:
    image: wordpress # staging 环境使用的镜像版本
    environment:
      WORDPRESS_DB_HOST: db:3306 # staging 环境的连接配置
    deploy:
      mode: replicated
      replicas: 1 # staging 环境不需要多个实例
```

```yaml
# prod.yaml 文件
version: "3.8"

services:
  wordpress:
    image: wordpress # production 环境使用的镜像版本
    environment:
      WORDPRESS_DB_HOST: online-db:3306 # production 环境的连接配置
    deploy:
      mode: replicated
      replicas: 3 # production 环境的实例数量
```

执行 `docker stack deploy -c base.yaml -c staging.yaml` 命令就是用 staging 环境的配置去部署，它会将 `base.yaml` 和 `staging.yaml` 的内容进行合并。将 `staging.yaml` 替换为 `prod.yaml` 就可以用 production 的配置进行部署了。

另外一个技巧是，如果一个 `compose` 文件定义了多个 service，那不同的 service 也可能有相同的重启策略、回滚策略等，这时可以用 `yaml` 的锚点技巧优化 `compose` 文件定义，例如

```yaml
# docker-compose.yaml
version: "3.8"

# 在 docker compose 文件中，以 x- 开头的字段会被识别为变量
x-deploy-defaults: &deploy-defaults
  restart_policy:
    condition: any
    delay: 5s
    max_attempts: 3
    window: 120s
  rollback_config:
    parallelism: 1
    delay: 0s
    monitor: 10s
    order: stop-first
  update_config:
    parallelism: 1
    delay: 10s
    monitor: 10s
    order: start-first

x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 5s
  retries: 3
  start_period: 10s

services:
  # 第一个服务
  wordpress:
    image: wordpress
    deploy:
      <<: *deploy-defaults # 插入前面定义的 deploy-defaults 变量
    healthcheck:
      <<: *healthcheck-defaults # 插入前面定义的 healthcheck-defaults 变量
      test: ["CMD", "curl", "-f", "http://localhost"]

  # 第二个服务
  wordpress-2:
    image: wordpress
    deploy:
      <<: *deploy-defaults # 插入前面定义的 deploy-defaults 变量
    healthcheck:
      <<: *healthcheck-defaults # 插入前面定义的 healthcheck-defaults 变量
      test: ["CMD", "curl", "-f", "http://localhost"]
```
